{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  \n",
    "import numpy as np  \n",
    "import random  \n",
    "import string\n",
    "\n",
    "import bs4 as bs  \n",
    "import urllib.request  \n",
    "import re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_html = urllib.request.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')  \n",
    "raw_html = raw_html.read()\n",
    "\n",
    "article_html = bs.BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "article_text = ''\n",
    "\n",
    "for para in article_paragraphs:  \n",
    "    article_text += para.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.sent_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus )):\n",
    "    corpus [i] = corpus [i].lower()\n",
    "    corpus [i] = re.sub(r'\\W',' ',corpus [i])\n",
    "    corpus [i] = re.sub(r'\\s+',' ',corpus [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12 in the early days many language processing systems were designed by symbolic methods i e the hand coding of a set of rules coupled with a dictionary lookup 13 14 such as by writing grammars or devising heuristic rules for stemming \n"
     ]
    }
   ],
   "source": [
    "print(corpus[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = {}\n",
    "for sentence in corpus:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    for token in tokens:\n",
    "        if token not in wordfreq.keys():\n",
    "            wordfreq[token] = 1\n",
    "        else:\n",
    "            wordfreq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 20, 'language': 28, 'processing': 16, 'nlp': 17, 'is': 15, 'a': 24, 'subfield': 1, 'of': 67, 'linguistics': 9, 'computer': 4, 'science': 3, 'and': 30, 'artificial': 2, 'intelligence': 4, 'concerned': 1, 'with': 10, 'the': 69, 'interactions': 1, 'between': 1, 'computers': 2, 'human': 2, 'in': 29, 'particular': 1, 'how': 2, 'to': 27, 'program': 1, 'process': 2, 'analyze': 2, 'large': 3, 'amounts': 1, 'data': 5, 'goal': 1, 'capable': 1, 'understanding': 4, 'contents': 1, 'documents': 4, 'including': 1, 'contextual': 1, 'nuances': 1, 'within': 1, 'them': 1, 'technology': 1, 'can': 5, 'then': 2, 'accurately': 1, 'extract': 1, 'information': 1, 'insights': 1, 'contained': 1, 'as': 16, 'well': 2, 'categorize': 1, 'organize': 1, 'themselves': 1, 'challenges': 1, 'frequently': 2, 'involve': 2, 'speech': 5, 'recognition': 2, 'generation': 2, 'has': 6, 'its': 2, 'roots': 1, '1950s': 1, 'already': 1, '1950': 1, 'alan': 1, 'turing': 2, 'published': 1, 'an': 5, 'article': 1, 'titled': 1, 'computing': 1, 'machinery': 1, 'which': 5, 'proposed': 3, 'what': 1, 'now': 2, 'called': 2, 'test': 2, 'criterion': 1, 'though': 2, 'at': 1, 'time': 1, 'that': 15, 'was': 5, 'not': 1, 'articulated': 1, 'problem': 1, 'separate': 2, 'from': 4, 'includes': 1, 'task': 2, 'involves': 1, 'automated': 1, 'interpretation': 1, 'premise': 1, 'symbolic': 4, 'summarized': 1, 'by': 6, 'john': 1, 'searle': 1, 's': 2, 'chinese': 2, 'room': 1, 'experiment': 1, 'given': 3, 'collection': 1, 'rules': 9, 'e': 10, 'g': 9, 'phrasebook': 1, 'questions': 1, 'matching': 1, 'answers': 2, 'emulates': 1, 'or': 4, 'other': 1, 'tasks': 10, 'applying': 1, 'those': 1, 'it': 2, 'confronts': 1, 'up': 2, '1980s': 3, 'most': 3, 'systems': 6, 'were': 2, 'based': 7, 'on': 10, 'complex': 2, 'sets': 1, 'hand': 4, 'written': 2, 'starting': 1, 'late': 2, 'however': 5, 'there': 1, 'revolution': 2, 'introduction': 1, 'machine': 13, 'learning': 13, 'algorithms': 6, 'for': 11, 'this': 3, 'due': 2, 'both': 2, 'steady': 1, 'increase': 2, 'computational': 3, 'power': 1, 'see': 2, 'moore': 1, 'law': 1, 'gradual': 1, 'lessening': 1, 'dominance': 1, 'chomskyan': 1, 'theories': 1, 'transformational': 1, 'grammar': 4, 'whose': 1, 'theoretical': 1, 'underpinnings': 1, 'discouraged': 1, 'sort': 1, 'corpus': 2, 'underlies': 1, 'approach': 2, '6': 1, '2010s': 1, 'representation': 1, 'deep': 3, 'neural': 8, 'network': 2, 'style': 1, 'methods': 6, 'became': 1, 'widespread': 1, 'popularity': 2, 'partly': 1, 'flurry': 1, 'results': 4, 'showing': 1, 'such': 10, 'techniques': 2, '7': 1, '8': 1, 'achieve': 2, 'state': 1, 'art': 1, 'many': 6, 'modeling': 2, '9': 1, 'parsing': 2, '10': 1, '11': 1, 'increasingly': 4, 'important': 1, 'medicine': 1, 'healthcare': 1, 'where': 1, 'helps': 1, 'notes': 1, 'text': 1, 'electronic': 1, 'health': 1, 'records': 1, 'would': 1, 'otherwise': 1, 'be': 5, 'inaccessible': 1, 'study': 2, 'when': 4, 'seeking': 1, 'improve': 1, 'care': 1, '12': 1, 'early': 1, 'days': 1, 'designed': 2, 'i': 1, 'coding': 1, 'set': 3, 'coupled': 1, 'dictionary': 1, 'lookup': 1, '13': 1, '14': 1, 'writing': 1, 'grammars': 1, 'devising': 1, 'heuristic': 1, 'stemming': 1, 'more': 7, 'recent': 1, 'have': 9, 'advantages': 1, 'over': 1, 'produced': 2, 'despite': 1, 'research': 6, 'are': 9, 'still': 1, '2020': 2, 'commonly': 3, 'used': 4, 'since': 4, 'so': 1, 'statistical': 12, '15': 1, '16': 1, 'mid': 1, '1990s': 2, 'much': 1, 'relied': 1, 'heavily': 1, 'paradigm': 2, 'calls': 1, 'instead': 2, 'using': 1, 'inference': 1, 'automatically': 1, 'learn': 2, 'through': 3, 'analysis': 1, 'corpora': 1, 'plural': 1, 'form': 1, 'possibly': 1, 'annotations': 1, 'typical': 1, 'real': 5, 'world': 3, 'examples': 2, 'different': 2, 'classes': 1, 'been': 6, 'applied': 1, 'these': 2, 'take': 1, 'input': 6, 'features': 2, 'generated': 1, 'focused': 2, 'models': 9, 'make': 2, 'soft': 2, 'probabilistic': 2, 'decisions': 2, 'attaching': 2, 'valued': 3, 'weights': 2, 'each': 1, 'feature': 2, 'embeddings': 2, '17': 1, 'networks': 3, 'general': 1, 'also': 1, '18': 1, 'advantage': 1, 'they': 5, 'express': 1, 'relative': 1, 'certainty': 1, 'possible': 2, 'rather': 1, 'than': 1, 'only': 1, 'one': 2, 'producing': 1, 'reliable': 2, 'model': 1, 'included': 1, 'component': 1, 'larger': 3, 'system': 2, 'some': 4, 'earliest': 1, 'decision': 1, 'trees': 1, 'hard': 1, 'if': 1, 'similar': 1, 'existing': 1, 'part': 3, 'tagging': 2, 'introduced': 1, 'use': 2, 'hidden': 1, 'markov': 1, 'making': 1, 'cache': 1, 'upon': 1, 'rely': 1, 'generally': 1, 'robust': 1, 'unfamiliar': 1, 'especially': 2, 'contains': 1, 'errors': 1, 'very': 1, 'common': 1, 'produce': 1, 'integrated': 1, 'into': 2, 'comprising': 1, 'multiple': 1, 'subtasks': 2, 'turn': 2, 'largely': 2, 'replaced': 1, 'continue': 1, 'relevant': 1, 'contexts': 1, 'interpretability': 1, 'transparency': 1, 'required': 1, 'major': 2, 'drawback': 1, 'require': 1, 'elaborate': 1, 'engineering': 1, '2015': 1, '19': 1, 'field': 2, 'thus': 1, 'abandoned': 1, 'shifted': 1, 'popular': 1, 'include': 1, 'word': 2, 'capture': 1, 'semantic': 1, 'properties': 1, 'words': 1, 'end': 2, 'higher': 2, 'level': 2, 'question': 1, 'answering': 1, 'relying': 1, 'pipeline': 1, 'intermediate': 2, 'dependency': 1, 'areas': 1, 'shift': 1, 'entailed': 1, 'substantial': 1, 'changes': 1, 'approaches': 3, 'may': 1, 'viewed': 1, 'new': 1, 'distinct': 1, 'instance': 1, 'term': 1, 'translation': 3, 'nmt': 1, 'emphasizes': 1, 'fact': 1, 'directly': 1, 'sequence': 2, 'transformations': 1, 'obviating': 1, 'need': 1, 'steps': 1, 'alignment': 1, 'smt': 1, 'following': 1, 'list': 1, 'researched': 1, 'direct': 1, 'applications': 2, 'while': 1, 'others': 1, 'serve': 1, 'aid': 1, 'solving': 1, 'closely': 1, 'intertwined': 1, 'subdivided': 1, 'categories': 1, 'convenience': 1, 'coarse': 1, 'division': 1, 'below': 1, 'long': 2, 'standing': 2, 'trends': 3, 'extrapolate': 1, 'future': 1, 'directions': 1, 'three': 1, 'among': 2, 'topics': 1, 'series': 1, 'conll': 2, 'shared': 2, 'observed': 1, '38': 1, 'aspects': 3, 'emulate': 1, 'intelligent': 1, 'behaviour': 2, 'apparent': 1, 'comprehension': 1, 'broadly': 1, 'speaking': 1, 'technical': 1, 'operationalization': 1, 'advanced': 1, 'cognitive': 13, 'represents': 1, 'developmental': 1, 'trajectories': 1, 'above': 1, 'cognition': 1, 'refers': 1, 'mental': 1, 'action': 1, 'acquiring': 1, 'knowledge': 2, 'thought': 1, 'experience': 1, 'senses': 1, '39': 1, 'interdisciplinary': 2, 'scientific': 1, 'mind': 1, 'processes': 1, '40': 1, 'branch': 1, 'combining': 1, 'psychology': 1, '41': 1, 'during': 2, 'age': 1, 'area': 1, 'maintained': 1, 'strong': 1, 'ties': 2, 'studies': 1, 'example': 1, 'george': 1, 'lakoff': 1, 'offers': 1, 'methodology': 1, 'build': 1, 'perspective': 1, 'along': 1, 'findings': 1, '42': 1, 'two': 1, 'defining': 1, 'historical': 1, 'heritage': 1, 'but': 1, 'less': 1, 'addressed': 1, 'nevertheless': 1, 'develop': 1, 'towards': 1, 'technically': 1, 'operationalizable': 1, 'frameworks': 2, 'pursued': 1, 'context': 1, 'various': 1, '44': 1, 'functional': 1, '45': 1, 'construction': 1, '46': 1, 'psycholinguistics': 1, 'neuroscience': 1, 'act': 1, 'r': 1, 'limited': 1, 'uptake': 1, 'mainstream': 1, 'measured': 1, 'presence': 1, 'conferences': 1, '47': 1, 'acl': 1, 'recently': 1, 'ideas': 2, 'revived': 1, 'explainability': 1, 'under': 1, 'notion': 1, 'ai': 1, '48': 1, 'likewise': 1, 'inherent': 1, 'multimodal': 1, 'although': 1, 'rarely': 1, 'made': 1, 'explicit': 1, '49': 1}\n"
     ]
    }
   ],
   "source": [
    "print(wordfreq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5904c03de541aee3171dc2d946da9df85831543bc9d72f4542217b15b1550de6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
